{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c78048ce",
   "metadata": {},
   "source": [
    "Now we are going to go and standardise and normalise these images using this resizing and normalisation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcbe704",
   "metadata": {},
   "source": [
    "Lets import all our required modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# numerical\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# torch\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, datasets, transforms\n",
    "\n",
    "# resnet\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "#pil\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True # got a weird error sometimes if i dindt have this\n",
    "\n",
    "# scikit-learn\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    davies_bouldin_score,\n",
    "    silhouette_score,\n",
    "    normalized_mutual_info_score,\n",
    "    adjusted_rand_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7c4f8a",
   "metadata": {},
   "source": [
    "And then we are going to set our Random seed. This makes our tests reproducable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ec2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 67\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91079e31",
   "metadata": {},
   "source": [
    "this is our transform in order to normalse the data. We scale these images to 224x224 ( as this is the resnet input size )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c20dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform  = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ff6f5",
   "metadata": {},
   "source": [
    "Now we check if CUDA is available, and define our extract features function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec743ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(\"Using:\", device)\n",
    "\n",
    "# Prepare Model (remove final layer for features)\n",
    "resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model = nn.Sequential(*(list(resnet.children())[:-1]))  # outputs [batch, 2048, 1, 1]\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "def extract_features(batch_images):\n",
    "    with torch.no_grad():\n",
    "        batch_images = batch_images.to(device)\n",
    "        feats = model(batch_images)                 # [batch, 2048, 1, 1]\n",
    "        feats = feats.reshape(feats.size(0), -1)    # [batch, 2048]\n",
    "        return feats.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f800ec2",
   "metadata": {},
   "source": [
    "Now to check if the image folder exists, and load the images.\n",
    "We will load from disk if the feature extraction has been done already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/cats-and-dogs\"):\n",
    "    raise FileNotFoundError(\"cats-and-dogs image folder not found\")\n",
    "\n",
    "dataset_info = datasets.ImageFolder(\"data/cats-and-dogs\", transform=transform)\n",
    "counts = {}\n",
    "\n",
    "for _ , label in dataset_info.samples:\n",
    "    counts[label] = counts.get(label, 0) + 1\n",
    "\n",
    "name_counts = {dataset_info.classes[i]: counts.get(i, 0) for i in range(len(dataset_info.classes))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215fc9e",
   "metadata": {},
   "source": [
    "We now have to extract features.\n",
    "We check a file first as this is an expensive computation that doesnt need repeating needlessly.\n",
    "We use TQDM in order to provide us with a progress bar. This is essential for long operations such as this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cbff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FORCE_EXTRACT = False       # change to true if you have made changes to the feature extraction\n",
    "\n",
    "\n",
    "dataset = datasets.ImageFolder(\"data/cats-and-dogs\", transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "if (not FORCE_EXTRACT) and os.path.exists(\"data/features/cats-and-dogs_features.npy\") and os.path.exists(\"data/features/cats-and-dogs_labels.npy\"):\n",
    "    train_features = np.load(\"data/features/cats-and-dogs_features.npy\")\n",
    "    train_labels = np.load(\"data/features/cats-and-dogs_labels.npy\")\n",
    "    print(\"Loaded features from file.\")\n",
    "\n",
    "else:\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Extracting features\"):\n",
    "        batch_feats = extract_features(imgs)\n",
    "        train_features.append(batch_feats)\n",
    "        train_labels.append(labels.numpy())\n",
    "\n",
    "    train_features = np.concatenate(train_features, axis=0)\n",
    "    train_labels = np.concatenate(train_labels, axis=0)\n",
    "\n",
    "    print(\"Feature vectors shape:\", train_features.shape)\n",
    "    print(\"Labels shape:\", train_labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "    os.makedirs(\"data/features\", exist_ok=True)\n",
    "    np.save(\"data/features/cats-and-dogs_features.npy\", train_features)\n",
    "    np.save(\"data/features/cats-and-dogs_labels.npy\", train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f5373",
   "metadata": {},
   "source": [
    "Now we will try a few methods of dimensionality reduction.\n",
    "We will use T-SNE, PCA and UMAP and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75763764",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_components=2, random_state=67)\n",
    "features_2D_UMAP = reducer.fit_transform(train_features)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(features_2D_UMAP[:,0], features_2D_UMAP[:,1], c=train_labels, cmap='tab10', s=10, alpha=0.7)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.title(\"Feature space projected to 2D with UMAP\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f33b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reducer = PCA(n_components=0.95)\n",
    "features_2D_PCA = reducer.fit_transform(train_features)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(features_2D_PCA[:,0], features_2D_PCA[:,1], c=train_labels, cmap='tab10', s=10, alpha=0.7)\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.title(\"Feature space projected to 2D with PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-sne\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reducer = TSNE(n_components=2, random_state=67)\n",
    "features_2D_TSNE = reducer.fit_transform(train_features)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(features_2D_TSNE[:,0], features_2D_TSNE[:,1], c=train_labels, cmap='tab10', s=10, alpha=0.7)\n",
    "plt.xlabel(\"T-SNE 1\")\n",
    "plt.ylabel(\"T-SNE 2\")\n",
    "plt.title(\"Feature space projected to 2D with T-SNE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf30c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_clusters = len(np.unique(train_labels))  # or choose the “true” number or experiment with k\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(features_2D_UMAP)  # features_2D from UMAP/PCA/t-SNE\n",
    "\n",
    "# Visualize clusters\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(features_2D_UMAP[:,0], features_2D_UMAP[:,1], c=cluster_labels, cmap='tab20', s=12, alpha=0.8)\n",
    "plt.title('K-Means Clusters in UMAP Space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db_score = davies_bouldin_score(features_2D_UMAP, cluster_labels)\n",
    "sil_score = silhouette_score(features_2D_UMAP, cluster_labels)\n",
    "print(\"Davies-Bouldin Index:\", db_score)\n",
    "print(\"Silhouette Score:\", sil_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a843a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    train_features, train_labels, test_size=0.2, random_state=67, stratify=train_labels\n",
    ")\n",
    "\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, multi_class=\"multinomial\", solver=\"lbfgs\", random_state=67))\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "joblib.dump(clf, \"catsanddogsmodel1.joblib\")\n",
    "print(\"Saved classifier\")\n",
    "\n",
    "\n",
    "y_test_pred = clf.predict(x_test)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred, target_names=dataset.classes))\n",
    "\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "ax.set_xticks(np.arange(len(dataset.classes)))\n",
    "ax.set_yticks(np.arange(len(dataset.classes)))\n",
    "ax.set_xticklabels(dataset.classes)\n",
    "ax.set_yticklabels(dataset.classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (test)')\n",
    "# annotate cells\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, f\"{cm[i,j]:d}\", ha='center', va='center', color='black')\n",
    "fig.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
